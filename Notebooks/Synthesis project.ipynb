{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vP_0tHxQo39T"
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"Data\")\n",
    "schedules_df = pd.read_excel(os.path.join(data_path, \"Schedules.xlsx\"))\n",
    "data_df = pd.read_excel(os.path.join(data_path, \"Data.xlsx\"))\n",
    "clients_df = pd.read_excel(os.path.join(data_path, \"Clients.xlsx\"))\n",
    "transl_cost_pairs_df = pd.read_excel(os.path.join(data_path, \"TranslatorsCost+Pairs.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envirinmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "TRANSLATORS_UNAVAILABLE = []\n",
    "\n",
    "wildcards = [None, \"Quality\", \"Time\", \"Cost\"]\n",
    "task_types = data_df[\"TASK_TYPE\"].unique()\n",
    "unique_language_pairs = data_df[[\"SOURCE_LANG\", \"TARGET_LANG\"]].drop_duplicates().reset_index(drop=True)\n",
    "min_qualities = [0, 7, 7.5, 8]\n",
    "pm = ['PMT', 'KMT', 'BMT', 'RMT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** `TRANSLATORS_UNAVAILABLE` is a list for keeping track of translators alredy assigned or performing a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO we have to think what to do with translators that can perform multiple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Information\n",
    "##### General Info\n",
    "- **PROJECT_ID**: Project code (additional info, likely not necessary).\n",
    "- **PM**: Responsible management team.\n",
    "- **TASK_ID**: Task code.\n",
    "##### Dates\n",
    "- **START**: Task start date.\n",
    "- **END**: Theoretical task delivery date (can be compared with `DELIVERED` to check for delays).\n",
    "##### Task Type (`TASK_TYPE`)\n",
    "Some considerations must be taken into account:\n",
    "- **DTP**: Desktop-Publishing tasks.\n",
    "- **Engineering**: Engineering tasks such as file conversions, coding, etc.\n",
    "- **LanguageLead**: Linguistic management tasks. Assigned to highly experienced and quality-oriented individuals who regularly work on the project.\n",
    "- **Management**: General management tasks.\n",
    "- **Miscellaneous**: Various linguistic tasks.\n",
    "- **PostEditing**: Post-editing tasks. Similar to Translation tasks but with slightly different skills required for the TRANSLATOR.\n",
    "- **ProofReading**: Full review of a Translation or PostEditing. Always follows a Translation or PostEditing. The TRANSLATOR assigned must have more \n",
    "experience than the person who performed the initial step.\n",
    "- **Spotcheck**: Partial review of a Translation or PostEditing. Similar conditions as ProofReading.\n",
    "- **TEST**: Test required to qualify for working with a client. Should be assigned to the most experienced and high-quality TRANSLATOR \n",
    "for the client or topic, regardless of price but considering the deadline.\n",
    "- **Training**: Translator experience and quality are not considered.\n",
    "- **Translation**: Translation task. The translator’s quality can be slightly lower if the ProofReading (not Spotcheck) is done by a superior. If \n",
    "Spotcheck is done, the required quality must be met.\n",
    "##### Languages\n",
    "- **SOURCE_LANG**: Source language.\n",
    "- **TARGET_LANG**: Target language.\n",
    "##### Workflow \n",
    "- **TRANSLATOR**: Translator responsible for the task.\n",
    "- **ASSIGNED**: Time when the task is assigned (pre-notice) to the TRANSLATOR.\n",
    "- **READY**: Time when the TRANSLATOR is notified they can start.\n",
    "- **WORKING**: Time when the TRANSLATOR starts the task.\n",
    "- **DELIVERED**: Time when the TRANSLATOR delivers the task.\n",
    "- **RECEIVED**: Time when the PM receives the task.\n",
    "- **CLOSE**: Time when the PM marks the task as completed.\n",
    "##### Cost & Quality\n",
    "- **FORECAST**: Estimated hours for completion.\n",
    "- **HOURLY_RATE**: Task hourly rate.\n",
    "- **COST**: Total task cost.\n",
    "- **QUALITY_EVALUATION**: Quality control evaluation.\n",
    "##### Client Info\n",
    "- **MANUFACTURER**: Client.\n",
    "- **MANUFACTURER_SECTOR**: Level 1 client categorization.\n",
    "- **MANUFACTURER_INDUSTRY_GROUP**: Level 2 client categorization.\n",
    "- **MANUFACTURER_INDUSTRY**: Level 3 client categorization.\n",
    "- **MANUFACTURER_SUBINDUSTRY**: Level 4 client categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self, PROJECT_ID, TASK_ID, ASSIGNED, END, SELLING_HOURLY_PRICE, MIN_QUALITY, WILDCARD, TASK_TYPE, SOURCE_LANG, TARGET_LANG, MANUFACTURER, MANUFACTURER_SECTOR, \n",
    "                 MANUFACTURER_INDUSTRY_GROUP, MANUFACTURER_INDUSTRY, MANUFACTURER_SUBINDUSTRY, START=None, PM=None, TRANSLATOR=None, READY=None, WORKING=None, DELIVERED=None, \n",
    "                 RECEIVED=None, CLOSE=None, FORECAST=None, HOURLY_RATE=None, COST=None, QUALITY_EVALUATION=None):\n",
    "        \"\"\"\n",
    "        A class used to represent a Task. \n",
    "        The arguments initialized to None are the information that is not given at the beginning\n",
    "        \"\"\"\n",
    "        self.ASSIGNED = ASSIGNED\n",
    "        self.TASK_TYPE = TASK_TYPE\n",
    "        self.SOURCE_LANG = SOURCE_LANG\n",
    "        self.TARGET_LANG = TARGET_LANG\n",
    "        self.MANUFACTURER = MANUFACTURER\n",
    "        self.MANUFACTURER_SECTOR = MANUFACTURER_SECTOR\n",
    "        self.MANUFACTURER_INDUSTRY_GROUP = MANUFACTURER_INDUSTRY_GROUP\n",
    "        self.MANUFACTURER_INDUSTRY = MANUFACTURER_INDUSTRY\n",
    "        self.MANUFACTURER_SUBINDUSTRY = MANUFACTURER_SUBINDUSTRY\n",
    "        self.MIN_QUALITY = MIN_QUALITY\n",
    "        self.WILDCARD = WILDCARD \n",
    "        self.SELLING_HOURLY_PRICE = SELLING_HOURLY_PRICE\n",
    "\n",
    "        self.END = END # not given\n",
    "        self.PROJECT_ID = PROJECT_ID # not given\n",
    "        self.START = START #not given\n",
    "        self.PM = PM # not given\n",
    "        self.TASK_ID = TASK_ID # not given\n",
    "        self.TRANSLATOR = TRANSLATOR # not given\n",
    "        self.READY = READY # not given\n",
    "        self.WORKING = WORKING # not given\n",
    "        self.DELIVERED = DELIVERED # not given\n",
    "        self.RECEIVED = RECEIVED # not given\n",
    "        self.CLOSE = CLOSE # not given\n",
    "        self.FORECAST = FORECAST # not given\n",
    "        self.HOURLY_RATE = HOURLY_RATE # not given\n",
    "        self.COST = COST # not given\n",
    "        self.QUALITY_EVALUATION = QUALITY_EVALUATION  # not given\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Task Details:\\n\"\n",
    "            f\"  - Task ID: {self.TASK_ID}\\n\"\n",
    "            f\"  - Type: {self.TASK_TYPE}\\n\"\n",
    "            f\"  - Sector: {self.MANUFACTURER_SECTOR}\\n\"\n",
    "            f\"  - Industry (Subsector): {self.MANUFACTURER_INDUSTRY}\\n\"\n",
    "            f\"  - Start: {self.START}\\n\"\n",
    "            f\"  - Budget: {self.SELLING_HOURLY_PRICE}\\n\"\n",
    "            f\"  - Quality: {self.MIN_QUALITY}\\n\"\n",
    "            f\"  - Wildcard: {self.WILDCARD}\\n\"\n",
    "            f\"  - Source Language: {self.SOURCE_LANG}\\n\"\n",
    "            f\"  - Target Language: {self.TARGET_LANG}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation (e.g., 80% train, 20% validation)\n",
    "train_df, validation_df = train_test_split(data_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_and_save_translator_labels(df, translator_column=\"TRANSLATOR\"):\n",
    "    \"\"\"\n",
    "    Extracts and removes translators from test_df, then saves them as a label dict.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing translator data.\n",
    "        translator_column (str): The column name that holds the translator labels.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The test_df without the translators column.\n",
    "        dict: Dictionary of translator labels {index: translators}\n",
    "    \"\"\"\n",
    "    if translator_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{translator_column}' not found in test_df.\")\n",
    "    \n",
    "    # Extract labels\n",
    "    translator_labels = df[translator_column].to_dict()\n",
    "    \n",
    "    # Drop the column from the DataFrame\n",
    "    df = df.drop(columns=[translator_column])\n",
    "    \n",
    "    return df, translator_labels\n",
    "\n",
    "train_df_clean, train_translator_labels = drop_and_save_translator_labels(train_df)\n",
    "validation_df_clean, validation_translator_labels = drop_and_save_translator_labels(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>PM</th>\n",
       "      <th>TASK_ID</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>TASK_TYPE</th>\n",
       "      <th>SOURCE_LANG</th>\n",
       "      <th>TARGET_LANG</th>\n",
       "      <th>ASSIGNED</th>\n",
       "      <th>READY</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>FORECAST</th>\n",
       "      <th>HOURLY_RATE</th>\n",
       "      <th>COST</th>\n",
       "      <th>QUALITY_EVALUATION</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>MANUFACTURER_SECTOR</th>\n",
       "      <th>MANUFACTURER_INDUSTRY_GROUP</th>\n",
       "      <th>MANUFACTURER_INDUSTRY</th>\n",
       "      <th>MANUFACTURER_SUBINDUSTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308387</th>\n",
       "      <td>217493</td>\n",
       "      <td>RMT</td>\n",
       "      <td>10749045</td>\n",
       "      <td>2019-06-20 13:36:00</td>\n",
       "      <td>2019-06-20 15:15:00</td>\n",
       "      <td>Translation</td>\n",
       "      <td>English</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>2019-06-20 13:57:56</td>\n",
       "      <td>2019-06-20 14:02:01</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-20 15:38:59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>17</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8</td>\n",
       "      <td>TrueConnect</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Interactive Media &amp; Services</td>\n",
       "      <td>Internet Services &amp; Infrastructure</td>\n",
       "      <td>Internet Services &amp; Infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445182</th>\n",
       "      <td>219796</td>\n",
       "      <td>PMT</td>\n",
       "      <td>11017600</td>\n",
       "      <td>2021-06-21 09:51:00</td>\n",
       "      <td>2021-06-25 17:00:00</td>\n",
       "      <td>Translation</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish (Iberian)</td>\n",
       "      <td>2021-06-22 09:45:13</td>\n",
       "      <td>2021-06-22 10:14:59</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-06-25 10:45:13</td>\n",
       "      <td>5.44</td>\n",
       "      <td>15</td>\n",
       "      <td>81.60</td>\n",
       "      <td>7</td>\n",
       "      <td>MotorForge</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Automobiles &amp; Components</td>\n",
       "      <td>Automobiles</td>\n",
       "      <td>Automobile Manufacturers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243409</th>\n",
       "      <td>216356</td>\n",
       "      <td>RMT</td>\n",
       "      <td>10608215</td>\n",
       "      <td>2018-03-21 09:56:00</td>\n",
       "      <td>2018-03-22 12:00:00</td>\n",
       "      <td>Translation</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish (Iberian)</td>\n",
       "      <td>2018-03-21 10:12:19</td>\n",
       "      <td>2018-03-21 10:12:28</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-22 12:43:01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>17</td>\n",
       "      <td>8.50</td>\n",
       "      <td>7</td>\n",
       "      <td>TrueConnect</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Interactive Media &amp; Services</td>\n",
       "      <td>Internet Services &amp; Infrastructure</td>\n",
       "      <td>Internet Services &amp; Infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206327</th>\n",
       "      <td>215492</td>\n",
       "      <td>KMT</td>\n",
       "      <td>10530327</td>\n",
       "      <td>2017-05-25 16:00:00</td>\n",
       "      <td>2017-05-29 14:00:00</td>\n",
       "      <td>ProofReading</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish (Iberian)</td>\n",
       "      <td>2017-05-24 13:13:35</td>\n",
       "      <td>2017-05-25 13:17:42</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-05-29 15:38:40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>15</td>\n",
       "      <td>5.40</td>\n",
       "      <td>8</td>\n",
       "      <td>Mercury Rail</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318763</th>\n",
       "      <td>218225</td>\n",
       "      <td>KMT</td>\n",
       "      <td>10773972</td>\n",
       "      <td>2019-08-28 16:41:00</td>\n",
       "      <td>2019-08-29 10:00:00</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>English</td>\n",
       "      <td>Spanish (Iberian)</td>\n",
       "      <td>2019-08-28 16:41:32</td>\n",
       "      <td>2019-08-28 16:43:49</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-08-29 09:12:36</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6</td>\n",
       "      <td>VitalSign Innovations</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment &amp; Supplies</td>\n",
       "      <td>Health Care Equipment &amp; Supplies</td>\n",
       "      <td>Health Care Equipment &amp; Supplies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PROJECT_ID   PM   TASK_ID                START                 END  \\\n",
       "308387     217493  RMT  10749045  2019-06-20 13:36:00 2019-06-20 15:15:00   \n",
       "445182     219796  PMT  11017600  2021-06-21 09:51:00 2021-06-25 17:00:00   \n",
       "243409     216356  RMT  10608215  2018-03-21 09:56:00 2018-03-22 12:00:00   \n",
       "206327     215492  KMT  10530327  2017-05-25 16:00:00 2017-05-29 14:00:00   \n",
       "318763     218225  KMT  10773972  2019-08-28 16:41:00 2019-08-29 10:00:00   \n",
       "\n",
       "            TASK_TYPE SOURCE_LANG        TARGET_LANG            ASSIGNED  \\\n",
       "308387    Translation     English            Catalan 2019-06-20 13:57:56   \n",
       "445182    Translation     English  Spanish (Iberian) 2021-06-22 09:45:13   \n",
       "243409    Translation     English  Spanish (Iberian) 2018-03-21 10:12:19   \n",
       "206327   ProofReading     English  Spanish (Iberian) 2017-05-24 13:13:35   \n",
       "318763  Miscellaneous     English  Spanish (Iberian) 2019-08-28 16:41:32   \n",
       "\n",
       "                     READY  ...               CLOSE FORECAST HOURLY_RATE  \\\n",
       "308387 2019-06-20 14:02:01  ... 2019-06-20 15:38:59     0.49          17   \n",
       "445182 2021-06-22 10:14:59  ... 2021-06-25 10:45:13     5.44          15   \n",
       "243409 2018-03-21 10:12:28  ... 2018-03-22 12:43:01     0.50          17   \n",
       "206327 2017-05-25 13:17:42  ... 2017-05-29 15:38:40     0.36          15   \n",
       "318763 2019-08-28 16:43:49  ... 2019-08-29 09:12:36     0.25          15   \n",
       "\n",
       "         COST  QUALITY_EVALUATION           MANUFACTURER  \\\n",
       "308387   8.33                   8            TrueConnect   \n",
       "445182  81.60                   7             MotorForge   \n",
       "243409   8.50                   7            TrueConnect   \n",
       "206327   5.40                   8           Mercury Rail   \n",
       "318763   3.75                   6  VitalSign Innovations   \n",
       "\n",
       "           MANUFACTURER_SECTOR       MANUFACTURER_INDUSTRY_GROUP  \\\n",
       "308387  Communication Services      Interactive Media & Services   \n",
       "445182  Consumer Discretionary          Automobiles & Components   \n",
       "243409  Communication Services      Interactive Media & Services   \n",
       "206327             Industrials          Industrial Conglomerates   \n",
       "318763             Health Care  Health Care Equipment & Supplies   \n",
       "\n",
       "                     MANUFACTURER_INDUSTRY            MANUFACTURER_SUBINDUSTRY  \n",
       "308387  Internet Services & Infrastructure  Internet Services & Infrastructure  \n",
       "445182                         Automobiles            Automobile Manufacturers  \n",
       "243409  Internet Services & Infrastructure  Internet Services & Infrastructure  \n",
       "206327            Industrial Conglomerates            Industrial Conglomerates  \n",
       "318763    Health Care Equipment & Supplies    Health Care Equipment & Supplies  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Index: 308387, Translator: Daiana Rosario\n",
      "Task Index: 445182, Translator: Laurina Santiago\n",
      "Task Index: 243409, Translator: Nieves Leocadia\n",
      "Task Index: 206327, Translator: Almudena Fiamma\n",
      "Task Index: 318763, Translator: Abelardo\n",
      "Task Index: 256003, Translator: Connor\n",
      "Task Index: 532685, Translator: Artur Fulgencio\n",
      "Task Index: 514381, Translator: Sussana\n",
      "Task Index: 437780, Translator: Guillermo\n",
      "Task Index: 61640, Translator: Nieves Leocadia\n",
      "Task Index: 404833, Translator: Casiano\n"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(train_translator_labels.items()):\n",
    "    print(f\"Task Index: {key}, Translator: {value}\")\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of what is happening\n",
    "\n",
    "In the global scope:\n",
    "\n",
    "0. We use as base of useful features the dataframe `transl_cost_pairs_df`\n",
    "It includes:\n",
    "- TRANSLATOR: Translator name.\n",
    "- SOURCE_LANG: Source language.\n",
    "- TARGET_LANG: Target language.\n",
    "- HOURLY_RATE: Cost per hour.\n",
    "\n",
    "\n",
    "1. We compute the **average proportional delay** (speed) from the `data_df` for each translator and merge it with this base dataframe\n",
    "\n",
    "\n",
    "Now for the each task:\n",
    "\n",
    "2. We start to the strict filter:\n",
    "    - Filter of **languages**: only consider the translators who offer this translation\n",
    "    - Filter of **price**: only consider the prices below the threshold\n",
    "    - Filter of **quality** by language: this is done by making an average of the quality of these languages for each translator, and then using it as a threshold. \n",
    "    - Filter of **availability**: if the taks lasts less than 7 days we check whether the translator will even work before the theoretical deadline (it is 7 days because everyone works at least once a week)\n",
    "\n",
    "3. We do a **weighted knn**:\n",
    "    - We do it on the *perfect point* (price = 0, quality = 10, speed = 100%, experience = 10... (orientative values))\n",
    "    - The weights are chosen by the wildcards and by the expereince required for the type of task\n",
    "        A weighted knn, after normalizing, it distorts the chosen axis size to give more or less weight. \n",
    "    - The similarity score is the final ranking. \n",
    "\n",
    "4. Outcome possibilities: ***(work in progress)***\n",
    "    - We get None or too few translators: if it is None we use the wildcard to completely ignore that factor in the strict filter\n",
    "    - We get a lot of translators: (we need the rest of features to give better recommendations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- THESE ARE GENERAL FUNCTIONS THAT CAN BE USED TO ACTUALIZE THE DATA IF NEW TASKS WERE ADDED TO THE DATASET -----\n",
    "def compute_delay_percentage(data_df):\n",
    "    \"\"\"\n",
    "    Compute the delay_percentage of each translator based on the average time taken to complete tasks. \n",
    "    This is the time overrun percentage: Negative values mean the task was early, positives mean it was late. \n",
    "    \n",
    "    Args:\n",
    "        data_df (pd.DataFrame):\n",
    "            DataFrame containing the data of the tasks (to actualize data).\n",
    "        \n",
    "    Returns:\n",
    "        translators_attributes_df (pd.DataFrame) with the delay_percentage.\n",
    "    \"\"\"\n",
    "    date_cols = ['START', 'END', 'DELIVERED']\n",
    "    for col in date_cols:\n",
    "        data_df[col] = pd.to_datetime(data_df[col], errors='coerce')  # convert str a Timestamps\n",
    "        \n",
    "    # Compute the time overrun percentage of each task\n",
    "    # Avoid division by zero\n",
    "    duration = data_df['END'] - data_df['START']\n",
    "    duration = duration.replace(pd.Timedelta(0), pd.NaT)  # Avoid zero duration\n",
    "    data_df['DELAY_PERCENTAGE'] = ((data_df['DELIVERED'] - data_df['END']) / (duration)) * 100\n",
    "\n",
    "    data_df['DELAY_PERCENTAGE'] = data_df['DELAY_PERCENTAGE'].replace([np.inf, np.nan], 0)  # Replace inf and NaN with 0\n",
    "\n",
    "    # Limit the delay percentage to 100%\n",
    "    data_df['DELAY_PERCENTAGE'] = data_df['DELAY_PERCENTAGE'].clip(upper=100)  # Limit to 100% -> double the time predicted\n",
    "\n",
    "    # Compute the mean delay percentage for each translator\n",
    "    avg_delay_by_translator = data_df.groupby('TRANSLATOR')['DELAY_PERCENTAGE'].mean().reset_index()\n",
    "    avg_delay_by_translator['DELAY_PERCENTAGE'] = avg_delay_by_translator['DELAY_PERCENTAGE'].round(2)\n",
    "\n",
    "    # Rename the column for clarity\n",
    "    avg_delay_by_translator.rename(columns={'DELAY_PERCENTAGE': 'AVG_DELAY_PERCENTAGE'}, inplace=True)\n",
    "\n",
    "    # Merge the average delay with the translator cost pairs DataFrame\n",
    "    translators_attributes_df = transl_cost_pairs_df.merge(avg_delay_by_translator, on='TRANSLATOR', how='left')\n",
    "\n",
    "    #TAKE INTO ACCOUNT: Task count is added to the dataset to help judge reliability (e.g if the quality of translator is calculated using a few tasks). \n",
    "    return translators_attributes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1742052911892,
     "user": {
      "displayName": "Rime Slaoui",
      "userId": "06907206809915164567"
     },
     "user_tz": -60
    },
    "id": "DdpXWG2XyfuP",
    "outputId": "704065d5-17d5-4fe8-fd7c-f45157aa07f6"
   },
   "outputs": [],
   "source": [
    "# ----- THESE ARE FUNCTIONS TO CALCULATE QUALITY AND EXPERIENCE ONCE MADE THE GENERAL FILTERING -----\n",
    "def compute_number_tasks(data_df, df_filtered):\n",
    "    \"\"\"\n",
    "    Computes the number of tasks for each translator.\n",
    "    \n",
    "    Args:\n",
    "        data_df (pd.DataFrame): \n",
    "            DataFrame containing the data of the tasks.\n",
    "        df_filtered (pd.DataFrame): \n",
    "            DataFrame containing the filtered translators' attributes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            The filtered DataFrame (`df_filtered`) with the number of tasks performed for each translator.\n",
    "    \"\"\"\n",
    "    # Count the number of tasks each translator has done\n",
    "    task_counts = data_df.groupby('TRANSLATOR').size().reset_index(name='NUM_TASKS')\n",
    "\n",
    "    # Merge the task counts into the filtered dataframe\n",
    "    df_filtered = df_filtered.merge(task_counts, on='TRANSLATOR', how='left')\n",
    "\n",
    "    # Fill missing values (i.e., translators with no tasks) with 0\n",
    "    df_filtered['NUM_TASKS'] = df_filtered['NUM_TASKS'].fillna(0).astype(int)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def compute_quality_by_languages(df_filtered, source_lang, target_lang):\n",
    "    \"\"\"\n",
    "    Computes average quality for a given language pair (source_lang → target_lang).\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): Filtered translators.\n",
    "        source_lang (str): Source language.\n",
    "        target_lang (str): Target language.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Same df_filtered with new 'AVG_QUALITY_BY_LG' column.\n",
    "    \"\"\"\n",
    "    # Filter original dataframe by the language pair and translators in df_filtered\n",
    "    mask_lang_pair = (\n",
    "        (data_df['SOURCE_LANG'] == source_lang) &\n",
    "        (data_df['TARGET_LANG'] == target_lang) &\n",
    "        (data_df['TRANSLATOR'].isin(df_filtered['TRANSLATOR']))\n",
    "    )\n",
    "\n",
    "    # Compute the average quality for each translator in the filtered dataframe\n",
    "    avg_quality = (\n",
    "        data_df[mask_lang_pair]\n",
    "        .groupby('TRANSLATOR')['QUALITY_EVALUATION']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    # Assing the average quality to the filtered df\n",
    "    df_filtered['AVG_QUALITY_BY_LG'] = df_filtered['TRANSLATOR'].map(avg_quality)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def compute_quality_by_task_type(df_filtered, task_type):\n",
    "    \"\"\"\n",
    "    Computes the average quality for each translator for a given task type.\n",
    "    If the translator has no experience with that task, falls back to:\n",
    "      - their overall average quality (with a penalty), or\n",
    "      - the global average quality (with a stronger penalty).\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): DataFrame with filtered translators.\n",
    "        task_type (str): The specific task type to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: df_filtered with 'AVG_QUALITY_BY_TASK' and 'QUALITY_SOURCE_TASK'.\n",
    "    \"\"\"\n",
    "    translators = df_filtered['TRANSLATOR'].unique()\n",
    "\n",
    "    # 1. Compute average quality for given task type\n",
    "    mask_task = (\n",
    "        (data_df['TASK_TYPE'] == task_type) &\n",
    "        (data_df['TRANSLATOR'].isin(translators))\n",
    "    )\n",
    "\n",
    "    avg_by_task = (\n",
    "        data_df[mask_task]\n",
    "        .groupby('TRANSLATOR')['QUALITY_EVALUATION']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    df_filtered['AVG_QUALITY_BY_TASK'] = df_filtered['TRANSLATOR'].map(avg_by_task)\n",
    "    df_filtered['QUALITY_SOURCE_TASK'] = 'original'\n",
    "\n",
    "    # 2. Fallback to penalized overall average\n",
    "    mask_missing = df_filtered['AVG_QUALITY_BY_TASK'].isna()\n",
    "\n",
    "    overall_avg = (\n",
    "        data_df[data_df['TRANSLATOR'].isin(translators)]\n",
    "        .groupby('TRANSLATOR')['QUALITY_EVALUATION']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .apply(lambda x: x - 1 if pd.notnull(x) else None)  # configurable penalization, for flexibility\n",
    "        #For a data-driven approach, use can standard deviation or percentile-based penalization to adapt to the distribution of quality scores\n",
    "    )\n",
    "\n",
    "    df_filtered.loc[mask_missing, 'AVG_QUALITY_BY_TASK'] = df_filtered.loc[mask_missing, 'TRANSLATOR'].map(overall_avg)\n",
    "    df_filtered.loc[mask_missing, 'QUALITY_SOURCE_TASK'] = 'overall_penalized'\n",
    "\n",
    "    # 3. Fallback to global average (penalized)\n",
    "    mask_global = df_filtered['AVG_QUALITY_BY_TASK'].isna()\n",
    "    global_mean = data_df['QUALITY_EVALUATION'].mean()\n",
    "\n",
    "    df_filtered.loc[mask_global, 'AVG_QUALITY_BY_TASK'] = global_mean - 1.5  #Same as the other penalization, can be configured\n",
    "    df_filtered.loc[mask_global, 'QUALITY_SOURCE_TASK'] = 'global_penalized'\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def compute_experience(df_filtered, task_type, source_lang, target_lang, industry, subindustry):\n",
    "    \"\"\"\n",
    "    Computes a soft experience score for each translator based on how many\n",
    "    dimensions match (task_type, language pair, industry, subindustry).\n",
    "\n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): Filtered translators' dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: With added column 'EXPERIENCE_SCORE'.\n",
    "    \"\"\"\n",
    "    TASK_TYPE_BONUS = {\n",
    "    'LanguageLead': 0.5,\n",
    "    'ProofReading': 0.5,\n",
    "    'Spotcheck': 0.5\n",
    "    }\n",
    "    \n",
    "    translators = df_filtered['TRANSLATOR'].unique()\n",
    "    df = data_df[data_df['TRANSLATOR'].isin(translators)].copy()\n",
    "\n",
    "    # Base score: match on source, target, task_type\n",
    "    df['score'] = 0\n",
    "    df['score'] += (df['SOURCE_LANG'] == source_lang).astype(int)\n",
    "    df['score'] += (df['TARGET_LANG'] == target_lang).astype(int)\n",
    "    df['score'] += (df['TASK_TYPE'] == task_type).astype(int)\n",
    "\n",
    "    # Add only 1 point if either industry or subindustry match (but not double)\n",
    "    industry_match = (df['MANUFACTURER_INDUSTRY'] == industry)\n",
    "    subindustry_match = (df['MANUFACTURER_SUBINDUSTRY'] == subindustry)\n",
    "    df['score'] += ((industry_match | subindustry_match)).astype(int)\n",
    "\n",
    "    # Advanced task bonus\n",
    "    bonus_df = df[df['TASK_TYPE'].isin(TASK_TYPE_BONUS)]\n",
    "    bonus_df['bonus'] = bonus_df['TASK_TYPE'].map(TASK_TYPE_BONUS)\n",
    "    bonus_scores = bonus_df.groupby('TRANSLATOR')['bonus'].sum()\n",
    "\n",
    "    # Base score\n",
    "    base_scores = df.groupby('TRANSLATOR')['score'].sum()\n",
    "\n",
    "    # Total experience = base + bonus\n",
    "    total_score = base_scores.add(bonus_scores, fill_value=0)\n",
    "\n",
    "    df_filtered['EXPERIENCE_SCORE'] = df_filtered['TRANSLATOR'].map(total_score).fillna(0).round(2)\n",
    "\n",
    "    ## TODO normalize by the total number of tasks done ?? \n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def compute_experience_for_client(df_filtered, client):\n",
    "    \"\"\"\n",
    "    Computes an experience score for each translator based on a specific client\n",
    "\n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): Filtered translators' dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: With added column 'EXPERIENCE_CLIENT'.\n",
    "    \"\"\"\n",
    "    translators = df_filtered['TRANSLATOR'].unique()\n",
    "    df = data_df[data_df['TRANSLATOR'].isin(translators)].copy()\n",
    "\n",
    "\n",
    "    df['score'] = 0\n",
    "    df['score'] += (df['MANUFACTURER'] == client).astype(int)\n",
    "\n",
    "    # Total experience score = sum of weights per translator\n",
    "    experience_scores = df.groupby('TRANSLATOR')['score'].sum()\n",
    "\n",
    "    # Add to filtered dataframe\n",
    "    df_filtered['EXPERIENCE_CLIENT'] = df_filtered['TRANSLATOR'].map(experience_scores).fillna(0).astype(int)\n",
    "\n",
    "    # TODO: The normalization aso can be applied ???\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "\n",
    "# ----- PRINCIPAL FUNCTION TO FILTER THE TRANSLATORS' ATTRIBUTES -----\n",
    "def available_translators(task, translators_attributes_df, schedules_df, TRANSLATORS_UNAVAILABLE):\n",
    "    \"\"\"\n",
    "    Checks if translators are available for the task based on their weekly working schedule.\n",
    "    This, for now just takes into account the day of the week and the start time of the task. \n",
    "    TAKE INTO ACCOUNT: This can have problems if the translator is at the end of their weekly shedule, it also doesnt take into account multitasking.\n",
    "    \n",
    "    Args:\n",
    "        task (Task object): The task for which we want to check availability.\n",
    "        translators_attributes_df (pd.DataFrame): DataFrame containing the translators' attributes.\n",
    "        schedules_df (pd.DataFrame): DataFrame containing the weekly schedules of translators.\n",
    "        TRANSLATORS_UNAVAILABLE (list): List of translators who are unavailable.\n",
    "        \n",
    "    Returns:\n",
    "        df_filtered (pd.DataFrame): Filtered DataFrame containing translators who are available.\n",
    "    \"\"\"\n",
    "    # 1. Remove explicitly unavailable translators\n",
    "    ##TODO:check multitasking\n",
    "    df_filtered = translators_attributes_df[~translators_attributes_df['TRANSLATOR'].isin(TRANSLATORS_UNAVAILABLE)].copy()\n",
    "\n",
    "    # 2. Extract day of week and time from task\n",
    "    task_day = task.ASSIGNED.strftime('%a').upper()  #day of the week  e.g., 'MON', 'TUE'\n",
    "    task_start_time = task.ASSIGNED.time() #time of the day e.g., 10:00:00\n",
    "    task_end_time = task.ASSIGNED + timedelta(hours=1) #time of the day e.g., 11:00:00\n",
    "\n",
    "    # 3. Merge schedule info\n",
    "    df_filtered = df_filtered.merge(schedules_df, left_on='TRANSLATOR', right_on='NAME', how='left')\n",
    "\n",
    "    def is_available(row):\n",
    "        # 3.1 Check if works that day\n",
    "        if row[task_day] != 1:\n",
    "            return False\n",
    "\n",
    "        # 3.2 Parse working hours\n",
    "        work_start = row['START']\n",
    "        work_end = row['END']\n",
    "\n",
    "        task_start_time = timedelta(hours=task.ASSIGNED.hour, minutes=task.ASSIGNED.minute)\n",
    "        task_end_time = timedelta(hours=task.ASSIGNED.hour +1, minutes=task.ASSIGNED.minute)\n",
    "        work_start_time = timedelta(hours=row['START'].hour, minutes=row['START'].minute)\n",
    "        work_end_time = timedelta(hours=row['END'].hour, minutes=row['END'].minute)\n",
    "        \n",
    "        return (task_start_time >= work_start_time) and (task_end_time < work_end_time) #TODO ensure its not too close to the end of the shift, i dont know how to do this \n",
    "\n",
    "    # 4. Apply availability logic\n",
    "    df_filtered['IS_AVAILABLE'] = df_filtered.apply(is_available, axis=1)\n",
    "    df_filtered = df_filtered[df_filtered['IS_AVAILABLE'] == True].drop(columns=['IS_AVAILABLE'])\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def filter_language_price_quality_availability(data_df, schedules_df, translators_attributes_df, task = Task, need_wildcard = False):\n",
    "    \"\"\"\n",
    "    Filters the translators' attributes by languages, price, quality and availability.\n",
    "    If need_wildcard is True, it will skip the filter corresponding to the wildcard.\n",
    "    \n",
    "    Args:\n",
    "        translators_attributes_df (pd.DataFrame): \n",
    "            DataFrame containing the translators' attributes (name, languages, price, speed).\n",
    "        task (Task object): \n",
    "            The task for which we want to filter the translators.\n",
    "        need_wildcard (bool): \n",
    "            If True, skip the filter corresponding to the wildcard.\n",
    "            \n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            Filtered DataFrame containing translators who meet the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not need_wildcard:\n",
    "        # Filter by language, price HARD FILTER\n",
    "        df_filtered = translators_attributes_df[\n",
    "            (translators_attributes_df['SOURCE_LANG'] == task.SOURCE_LANG) & \n",
    "            (translators_attributes_df['TARGET_LANG'] == task.TARGET_LANG) &\n",
    "            (translators_attributes_df['HOURLY_RATE'] <= task.SELLING_HOURLY_PRICE) \n",
    "        ].copy()\n",
    "\n",
    "        df_filtered = compute_number_tasks(data_df, df_filtered)\n",
    "\n",
    "        # add the average quality column\n",
    "        df_filtered = compute_quality_by_task_type(df_filtered, task_type=task.TASK_TYPE)\n",
    "        df_filtered = compute_quality_by_languages(df_filtered, source_lang=task.SOURCE_LANG, target_lang=task.TARGET_LANG)\n",
    "\n",
    "        df_filtered = df_filtered[df_filtered['AVG_QUALITY_BY_LG'] >= task.MIN_QUALITY]\n",
    "        df_filtered = df_filtered[df_filtered['AVG_QUALITY_BY_TASK'] >= task.MIN_QUALITY]\n",
    "\n",
    "        # Filter by availability\n",
    "        df_filtered = available_translators(task, df_filtered, schedules_df, TRANSLATORS_UNAVAILABLE)\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    # same code as above but with the wildcard, it will skip the filter corresponding to the wildcard\n",
    "    else:\n",
    "        # if the wildcard is \"Price\", we don't filter by price\n",
    "        price_condition = (translators_attributes_df['HOURLY_RATE'] <= task.SELLING_HOURLY_PRICE) if task.WILDCARD != \"Price\" else True\n",
    "        # Filter by language, price \n",
    "        df_filtered = translators_attributes_df[\n",
    "            (translators_attributes_df['SOURCE_LANG'] == task.SOURCE_LANG) & \n",
    "            (translators_attributes_df['TARGET_LANG'] == task.TARGET_LANG) &\n",
    "            price_condition \n",
    "        ].copy()\n",
    "\n",
    "        translators_attributes_df = compute_number_tasks(train_df_clean, df_filtered)\n",
    "\n",
    "        if task.WILDCARD != \"Quality\":\n",
    "            # add the average quality column\n",
    "            df_filtered = compute_quality_by_languages(df_filtered, source_lang=task.SOURCE_LANG, target_lang=task.TARGET_LANG)\n",
    "            df_filtered = compute_quality_by_task_type(df_filtered, task_type=task.TASK_TYPE)\n",
    "\n",
    "            df_filtered = df_filtered[df_filtered['AVG_QUALITY_BY_LG'] >= task.MIN_QUALITY]\n",
    "            df_filtered = df_filtered[df_filtered['AVG_QUALITY_BY_TASK'] >= task.MIN_QUALITY]\n",
    "\n",
    "        if task.WILDCARD != \"Deadline\":\n",
    "            # Filter by availability\n",
    "            df_filtered = available_translators(task, df_filtered, schedules_df, TRANSLATORS_UNAVAILABLE)\n",
    "        \n",
    "        return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -------------- DEBUGG PART --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID                                                 219728\n",
      "PM                                                            BMT\n",
      "TASK_ID                                                  11057300\n",
      "START                                         2021-09-29 09:15:00\n",
      "END                                           2021-09-29 19:30:00\n",
      "TASK_TYPE                                             PostEditing\n",
      "SOURCE_LANG                                               English\n",
      "TARGET_LANG                                          Spanish (LA)\n",
      "ASSIGNED                                      2021-09-29 10:06:41\n",
      "READY                                         2021-09-29 10:06:48\n",
      "WORKING                                       2021-09-29 16:01:30\n",
      "DELIVERED                                     2021-09-29 19:44:06\n",
      "RECEIVED                                      2021-09-29 19:50:27\n",
      "CLOSE                                         2021-09-29 19:50:32\n",
      "FORECAST                                                     3.42\n",
      "HOURLY_RATE                                                    11\n",
      "COST                                                        37.62\n",
      "QUALITY_EVALUATION                                              4\n",
      "MANUFACTURER                                   NextGen Industries\n",
      "MANUFACTURER_SECTOR                        Consumer Discretionary\n",
      "MANUFACTURER_INDUSTRY_GROUP    Internet & Direct Marketing Retail\n",
      "MANUFACTURER_INDUSTRY          Internet & Direct Marketing Retail\n",
      "MANUFACTURER_SUBINDUSTRY       Internet & Direct Marketing Retail\n",
      "Name: 465939, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(validation_df_clean.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New task:\n",
      "Task Details:\n",
      "  - Task ID: 11057300\n",
      "  - Type: PostEditing\n",
      "  - Sector: Consumer Discretionary\n",
      "  - Industry (Subsector): Internet & Direct Marketing Retail\n",
      "  - Start: 2021-09-29 09:15:00\n",
      "  - Budget: 20\n",
      "  - Quality: 7.0\n",
      "  - Wildcard: Price\n",
      "  - Source Language: English\n",
      "  - Target Language: Spanish (LA)\n"
     ]
    }
   ],
   "source": [
    "translators_attributes_df = compute_delay_percentage(train_df)\n",
    "\n",
    "# Take a task from the validation set\n",
    "new_task = validation_df_clean.iloc[0].copy()\n",
    "new_task.to_dict()\n",
    "\n",
    "#Change the columns\n",
    "match = clients_df[clients_df['CLIENT_NAME'] == new_task['MANUFACTURER']]\n",
    "\n",
    "if not match.empty:\n",
    "    new_task['WILDCARD'] = match.iloc[0]['WILDCARD']\n",
    "    new_task['HOURLY_RATE'] = match.iloc[0]['SELLING_HOURLY_PRICE']\n",
    "    new_task['QUALITY_EVALUATION'] = match.iloc[0]['MIN_QUALITY']\n",
    "else:\n",
    "    print(\"WARNING: No match found in schedules_df for the given client. Setting default values.\")\n",
    "    # Default to a specific wildcard if no match is found\n",
    "    new_task['WILDCARD'] = 'Quality'\n",
    "    new_task['HOURLY_RATE'] = new_task['SELLING_HOURLY_PRICE']\n",
    "    new_task['QUALITY_EVALUATION'] = new_task['MIN_QUALITY']\n",
    "\n",
    "new_task['ASSIGNED'] = datetime.now()  # Sets to current datetime\n",
    "new_task = new_task.rename({'HOURLY_RATE': 'SELLING_HOURLY_PRICE'})\n",
    "new_task = new_task.rename({'QUALITY_EVALUATION': 'MIN_QUALITY'})\n",
    "\n",
    "# Convert to dict to use **kwargs\n",
    "# **kwargs: Pass a dictionary of named arguments (key=value) in a descomposed way (what we want here)\n",
    "new_task = Task(**new_task.to_dict())\n",
    "\n",
    "need_wildcard = False\n",
    "print(\"New task:\")\n",
    "print(new_task)\n",
    "\n",
    "df_filtered = filter_language_price_quality_availability(train_df, schedules_df, translators_attributes_df, new_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TRANSLATOR SOURCE_LANG   TARGET_LANG  HOURLY_RATE  \\\n",
      "0            Abdon     English  Spanish (LA)           17   \n",
      "1  Acacio Cayetano     English  Spanish (LA)           12   \n",
      "2     Alejo Esdras     English  Spanish (LA)           13   \n",
      "3     Alfonso Odon     English  Spanish (LA)           12   \n",
      "4  Almudena Fiamma     English  Spanish (LA)           15   \n",
      "\n",
      "   AVG_DELAY_PERCENTAGE  NUM_TASKS  AVG_QUALITY_BY_TASK QUALITY_SOURCE_TASK  \\\n",
      "0                -24.84         20                 7.42            original   \n",
      "1                -17.77        390                 7.03            original   \n",
      "2                -21.24        415                 7.47            original   \n",
      "3                 50.30          2                 7.00            original   \n",
      "4                -75.90       9288                 7.05            original   \n",
      "\n",
      "   AVG_QUALITY_BY_LG             NAME     START       END  MON  TUE  WED  THU  \\\n",
      "0               7.62            Abdon  10:00:00  20:00:00    1    1    1    1   \n",
      "1               7.17  Acacio Cayetano  08:00:00  18:00:00    1    1    1    1   \n",
      "2               7.60     Alejo Esdras  08:00:00  18:00:00    1    1    1    1   \n",
      "3               7.00     Alfonso Odon  10:00:00  20:00:00    1    0    0    1   \n",
      "4               7.04  Almudena Fiamma  09:00:00  19:00:00    1    1    1    1   \n",
      "\n",
      "   FRI  SAT  SUN  \n",
      "0    1    1    1  \n",
      "1    1    1    1  \n",
      "2    1    1    1  \n",
      "3    0    0    0  \n",
      "4    1    1    1  \n"
     ]
    }
   ],
   "source": [
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TRANSLATOR SOURCE_LANG   TARGET_LANG  HOURLY_RATE  \\\n",
      "0            Abdon     English  Spanish (LA)           17   \n",
      "1  Acacio Cayetano     English  Spanish (LA)           12   \n",
      "2     Alejo Esdras     English  Spanish (LA)           13   \n",
      "3     Alfonso Odon     English  Spanish (LA)           12   \n",
      "4  Almudena Fiamma     English  Spanish (LA)           15   \n",
      "\n",
      "   AVG_DELAY_PERCENTAGE  NUM_TASKS  AVG_QUALITY_BY_TASK QUALITY_SOURCE_TASK  \\\n",
      "0                -24.84         20                 7.42            original   \n",
      "1                -17.77        390                 7.03            original   \n",
      "2                -21.24        415                 7.47            original   \n",
      "3                 50.30          2                 7.00            original   \n",
      "4                -75.90       9288                 7.05            original   \n",
      "\n",
      "   AVG_QUALITY_BY_LG             NAME  ...       END MON  TUE  WED  THU  FRI  \\\n",
      "0               7.62            Abdon  ...  20:00:00   1    1    1    1    1   \n",
      "1               7.17  Acacio Cayetano  ...  18:00:00   1    1    1    1    1   \n",
      "2               7.60     Alejo Esdras  ...  18:00:00   1    1    1    1    1   \n",
      "3               7.00     Alfonso Odon  ...  20:00:00   1    0    0    1    0   \n",
      "4               7.04  Almudena Fiamma  ...  19:00:00   1    1    1    1    1   \n",
      "\n",
      "   SAT  SUN  EXPERIENCE_SCORE  EXPERIENCE_CLIENT  \n",
      "0    1    1              61.5                  2  \n",
      "1    1    1             774.5                 18  \n",
      "2    1    1             624.5                  0  \n",
      "3    0    0               5.0                  0  \n",
      "4    1    1           15093.0                  2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34642\\AppData\\Local\\Temp\\ipykernel_16036\\252473189.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bonus_df['bonus'] = bonus_df['TASK_TYPE'].map(TASK_TYPE_BONUS)\n"
     ]
    }
   ],
   "source": [
    "compute_experience(df_filtered, task_type=new_task.TASK_TYPE, source_lang=new_task.SOURCE_LANG, target_lang=new_task.TARGET_LANG, industry=new_task.MANUFACTURER_INDUSTRY, subindustry=new_task.MANUFACTURER_SUBINDUSTRY)\n",
    "compute_experience_for_client(df_filtered, client=new_task.MANUFACTURER)\n",
    "\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAt this stage, we have a filtered dataframe with the translators that are available for the task,\\nit contains the following columns:\\n    - TRANSLATOR: Name of the translator\\n    - SOURCE_LANG: Source language of the translator\\n    - TARGET_LANG: Target language of the translator\\n    - HOURLY_RATE: Hourly rate of the translator\\n    - Filtered by the availability\\n\\n    Things to take into account for the calculation of the scores:\\n    - AVG_QUALITY_BY_LNG: Average quality by language pair (if applicable)\\n    - AVG_QUALITY_BY_TASK: Average quality by task type (if applicable)\\n    - QUALITY_SOURCE_TASK: Source of the quality by task score (original, overall_penalized, global_penalized)\\n    - NUM_TASKS: Number of tasks performed by the translator (to take into account the reliability of the translator's quality and delay percentage, not experience because it is calculated based on specific tasks)\\n\\n    - EXPERIENCE_SCORE: Experience score based on task type, language pair, industry, and subindustry\\n    - EXPERIENCE_CLIENT: Experience score based on the specific client (if applicable)\\n    - AVG_DELAY_PERCENTAGE: Average delay percentage of the translator (if applicable)\\n\\n    \\nThere are some key considerations regarding the experience and quality weights:\\n    - Proofreading and Spotcheck need more expereinced translators.\\n    - LanguageLead is a more advanced task, so it needs more experience and quality.\\n    - Test should be assigned to the most experienced and high-quality TRANSLATOR for the client or topic, regardless of price.\\n    - For training we dont need to take into account the experience nor the quality\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "At this stage, we have a filtered dataframe with the translators that are available for the task,\n",
    "it contains the following columns:\n",
    "    - TRANSLATOR: Name of the translator\n",
    "    - SOURCE_LANG: Source language of the translator\n",
    "    - TARGET_LANG: Target language of the translator\n",
    "    - HOURLY_RATE: Hourly rate of the translator\n",
    "    - Filtered by the availability\n",
    "\n",
    "    Things to take into account for the calculation of the scores:\n",
    "    - AVG_QUALITY_BY_LNG: Average quality by language pair (if applicable)\n",
    "    - AVG_QUALITY_BY_TASK: Average quality by task type (if applicable)\n",
    "    - QUALITY_SOURCE_TASK: Source of the quality by task score (original, overall_penalized, global_penalized)\n",
    "    - NUM_TASKS: Number of tasks performed by the translator (to take into account the reliability of the translator's quality and delay percentage, not experience because it is calculated based on specific tasks)\n",
    "\n",
    "    - EXPERIENCE_SCORE: Experience score based on task type, language pair, industry, and subindustry\n",
    "    - EXPERIENCE_CLIENT: Experience score based on the specific client (if applicable)\n",
    "    - AVG_DELAY_PERCENTAGE: Average delay percentage of the translator (if applicable)\n",
    "\n",
    "    \n",
    "There are some key considerations regarding the experience and quality weights:\n",
    "    - Proofreading and Spotcheck need more expereinced translators.\n",
    "    - LanguageLead is a more advanced task, so it needs more experience and quality.\n",
    "    - Test should be assigned to the most experienced and high-quality TRANSLATOR for the client or topic, regardless of price.\n",
    "    - For training we dont need to take into account the experience nor the quality\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- KNN ----\n",
    "def knn(df_filtered, task, need_wildcard=False):\n",
    "    \"\"\"\n",
    "    Optimized KNN to find the best translators based on the task's requirements.\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): DataFrame containing the filtered translators' attributes.\n",
    "        task (Task object): The task for which we are finding suitable translators.\n",
    "        need_wildcard (bool): Whether to ignore the wildcard feature in KNN calculation.\n",
    "\n",
    "    Returns:\n",
    "        distances (np.ndarray): Distances of the nearest neighbors.\n",
    "        indexes (np.ndarray): Indices of the nearest neighbors in the original DataFrame.\n",
    "    \"\"\"\n",
    "    # Define features for the KNN\n",
    "    features = ['HOURLY_RATE', 'AVG_QUALITY_BY_LNG', 'AVG_QUALITY_BY_TASK', 'AVG_DELAY_PERCENTAGE', 'EXPERIENCE_SCORE', 'EXPERIENCE_CLIENT']\n",
    "    ideal_values = [1, 10, 10, -100, np.inf, np.inf]  # Ideal values for the features (price, quality, speed, experience), this is like the ideal translator\n",
    "    \n",
    "    # Initialize weights (weights for each feature)\n",
    "    weights = np.array([1, 1.5, 1.5, 0.25, 1, 0.5])  # Default weights for the features\n",
    "\n",
    "    # Adjust weights based on task type\n",
    "    if task.TASK_TYPE == 'ProofReading' or task.TASK_TYPE == 'Spotcheck':\n",
    "        # Higher weight for experience and quality\n",
    "        weights[4] *= 2  # Experience score weight increased\n",
    "        weights[1] *= 2  # Quality by language pair weight increased\n",
    "        weights[2] *= 2  # Quality by task weight increased\n",
    "    elif task.TASK_TYPE == 'LanguageLead':\n",
    "        # LanguageLead requires more experience and quality\n",
    "        weights[4] *= 2\n",
    "        weights[1] *= 2\n",
    "        weights[2] *= 2\n",
    "    elif task.TASK_TYPE == 'Test':\n",
    "        # Test task needs the highest experience and quality, ignore price\n",
    "        weights[0] = 0  # Price doesn't matter for Test\n",
    "        weights[1] *= 2  # Quality by language pair weight increased\n",
    "        weights[2] *= 2  # Quality by task weight increased\n",
    "        weights[4] *= 2  # Experience score weight increased\n",
    "    elif task.TASK_TYPE == 'Training':\n",
    "        # Training task doesn't consider experience or quality\n",
    "        weights[1] = 0  # Set quality to 0\n",
    "        weights[2] = 0  # Set quality to 0\n",
    "        weights[4] = 0  # Set experience to 0\n",
    "\n",
    "    # If wildcard is required, adjust the weights based on the wildcard preference\n",
    "    if not need_wildcard:\n",
    "        wildcard_vector = np.ones_like(weights)\n",
    "\n",
    "        if task.WILDCARD == 'Price':\n",
    "            wildcard_vector[0] = 0.25  # Price becomes less important\n",
    "        elif task.WILDCARD == 'Quality':\n",
    "            wildcard_vector[1] = 0.25  # Quality becomes less important\n",
    "        elif task.WILDCARD == 'Deadline':\n",
    "            wildcard_vector[3] = 0.25  # Deadline (Avg. Delay) becomes less important\n",
    "\n",
    "        weights = weights * wildcard_vector  # Apply adjusted weights based on wildcard\n",
    "\n",
    "    # Select features for the KNN calculation\n",
    "    X = df_filtered[features]\n",
    "\n",
    "    # Standardize the features (scaling)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_weighted = X_scaled * weights  # Apply the weights to scaled features\n",
    "\n",
    "    # Initialize and train the KNN model\n",
    "    knn = NearestNeighbors(metric='euclidean')\n",
    "    knn.fit(X_weighted)\n",
    "\n",
    "    # Define ideal task values as a DataFrame\n",
    "    task_df = pd.DataFrame([ideal_values], columns=features)\n",
    "    task_scaled = scaler.transform(task_df)\n",
    "    task_weighted = task_scaled * weights  # Weight the task ideal values too\n",
    "\n",
    "    # Find the nearest neighbors based on the task's ideal values\n",
    "    distances, indexes = knn.kneighbors(task_weighted, n_neighbors=len(df_filtered))  # Adjust the number of neighbors as needed\n",
    "\n",
    "    return distances, indexes\n",
    "\n",
    "\n",
    "def get_best_translators(df_filtered, indexes, distances):\n",
    "    \"\"\"\n",
    "    Get the best translators based on the KNN results.\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            Contains the filtered translators' attributes (name, language, price, quality, speed).\n",
    "        indexes (np.ndarray): \n",
    "            Indices of the nearest neighbors in the df_filtered.\n",
    "        distances (np.ndarray): \n",
    "            Distances of the nearest neighbors.\n",
    "            \n",
    "    Returns:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            Contains the filtered translators' attributes (name, language, price, quality, speed AND similarity_score).\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_translators = df_filtered.iloc[indexes[0]].copy()\n",
    "    \n",
    "    # Add the similarity score\n",
    "    selected_translators['Similarity Score'] = distances[0].round(2)  # Round to 2 decimal places\n",
    "\n",
    "    # Sort by similarity score (ascending: closest match first)\n",
    "    selected_translators = selected_translators.sort_values(by='Similarity Score', ascending=True) \n",
    "\n",
    "    return selected_translators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TRANSLATOR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ----- MAIN CODE ----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Creates a dataframe with  the additional attributes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m translators_attributes_df \u001b[38;5;241m=\u001b[39m compute_delay_percentage(train_df_clean)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Example of generating a task\u001b[39;00m\n\u001b[0;32m      6\u001b[0m new_task \u001b[38;5;241m=\u001b[39m validation_df_clean[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mcompute_delay_percentage\u001b[1;34m(data_df)\u001b[0m\n\u001b[0;32m     27\u001b[0m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY_PERCENTAGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY_PERCENTAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclip(upper\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Limit to 100% -> double the time predicted\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute the mean delay percentage for each translator\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m avg_delay_by_translator \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANSLATOR\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY_PERCENTAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     31\u001b[0m avg_delay_by_translator[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY_PERCENTAGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m avg_delay_by_translator[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDELAY_PERCENTAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Rename the column for clarity\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\34642\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   8879\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\34642\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1279\u001b[0m         obj,\n\u001b[0;32m   1280\u001b[0m         keys,\n\u001b[0;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1286\u001b[0m     )\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\34642\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TRANSLATOR'"
     ]
    }
   ],
   "source": [
    "# ----- MAIN CODE ----\n",
    "# Creates a dataframe with  the additional attributes\n",
    "translators_attributes_df = compute_delay_percentage(train_df_clean)\n",
    "\n",
    "# Example of generating a task\n",
    "new_task = validation_df_clean[0].copy()\n",
    "tasks = []\n",
    "tasks.append(new_task)\n",
    "\n",
    "for task in tasks:\n",
    "    need_wildcard = False\n",
    "    print(\"New task:\")\n",
    "    print(task)\n",
    "    df_filtered = filter_language_price_quality_availability(train_df_clean, schedules_df, translators_attributes_df, new_task)\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        print(\"\\nNo available translators. Possible reasons:\")\n",
    "        print(\"1. No translators available because the quality is too high\")\n",
    "        print(\"2. No translators available because the price is too low\")\n",
    "        print(\"\\nTrying with the wildcard...\\n\")        \n",
    "        need_wildcard = True\n",
    "        df_filtered = filter_language_price_quality_availability(translators_attributes_df, new_task, need_wildcard = need_wildcard)\n",
    "        if df_filtered.empty:\n",
    "            print(\"No available translators even with the wildcard\")\n",
    "            #TODO implement, see which is the strict filter or something inside the function to know the remedy\n",
    "            # ofrecer ignorando calidad, precio y deadline. Y si ni siquiera así hay, pues ofrecer otros idiomas parecidos (español vs argentino, english uk vs english us, etc.)\n",
    "            continue\n",
    "        \n",
    "    # Compute the KNN\n",
    "    distances, indexes = knn(df_filtered, task, need_wildcard = need_wildcard)\n",
    "\n",
    "    # Get the dataframe with the best translators\n",
    "    best_translators_df = get_best_translators(df_filtered, indexes, distances)\n",
    "    display(best_translators_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of mistakes in the dataset they have been mostly added to the analysis to keep things clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of them is that some of the translators (13) finish after 0am "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay algunos con fecha de START == END y si START > ASSIGNED (son errores porque no tiene sentido); pero si START <= ASSIGNED, \n",
    "# probablemente signifique que END (deadline) era urgente y no puso fecha límite, no son errores\n",
    "\n",
    "\n",
    "# provisionalmente cambiamos el START como ASSIGNED para estos casos\n",
    "# data_df.loc[data_df['START'] > data_df['ASSIGNED'], 'START'] = data_df['ASSIGNED'] \n",
    "\n",
    "## TODO we have to discuss this further, it have been added to data analysis but not shure how to address it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "actualize the unavailable translators:\n",
    "- add it to the list when one is selected by the client in the forntend\n",
    "- remove it from the list when the task has been finished "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
