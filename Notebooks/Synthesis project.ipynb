{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP_0tHxQo39T"
   },
   "outputs": [],
   "source": [
    "# Read excel\n",
    "data_path = os.path.join(\"..\", \"Data\")\n",
    "schedules_df = pd.read_excel(os.path.join(data_path, \"Schedules.xlsx\"))\n",
    "data_df = pd.read_excel(os.path.join(data_path, \"Data.xlsx\"))\n",
    "clients_df = pd.read_excel(os.path.join(data_path, \"Clients.xlsx\"))\n",
    "transl_cost_pairs_df = pd.read_excel(os.path.join(data_path, \"TranslatorsCost+Pairs.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildcards = [None, \"Quality\", \"Time\", \"Cost\"]\n",
    "task_types = data_df[\"TASK_TYPE\"].unique()\n",
    "unique_language_pairs = data_df[[\"SOURCE_LANG\", \"TARGET_LANG\"]].drop_duplicates().reset_index(drop=True)\n",
    "min_qualities = [0, 7, 7.5, 8]\n",
    "pm = ['PMT', 'KMT', 'BMT', 'RMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self, START, END, SELLING_HOURLY_PRICE, MIN_QUALITY, WILDCARD, TASK_TYPE, SOURCE_LANG, TARGET_LANG, MANUFACTURER, MANUFACTURER_SECTOR, \n",
    "                 MANUFACTURER_INDUSTRY_GROUP, MANUFACTURER_INDUSTRY, MANUFACTURER_SUBINDUSTRY, PM = None, PROJECT_ID = None, TASK_ID = None, TRANSLATOR=None, \n",
    "                 ASSIGNED=None, READY=None, WORKING=None, DELIVERED=None, RECEIVED=None, CLOSE=None, HOURS=None, \n",
    "                 HOURLY_RATE=None, COST=None, QUALITY_EVALUATION=None):\n",
    "        \"\"\"\n",
    "        A class used to represent a Task. \n",
    "        The arguments initialized to None are the information that is not given at the beginning\n",
    "        \"\"\"\n",
    "        self.PROJECT_ID = PROJECT_ID # not given\n",
    "        self.PM = PM # not given\n",
    "        self.TASK_ID = TASK_ID # not given\n",
    "        self.START = START\n",
    "        self.END = END # not given\n",
    "        self.TASK_TYPE = TASK_TYPE\n",
    "        self.SOURCE_LANG = SOURCE_LANG\n",
    "        self.TARGET_LANG = TARGET_LANG\n",
    "        self.TRANSLATOR = TRANSLATOR # not given\n",
    "        self.ASSIGNED = ASSIGNED # not given\n",
    "        self.READY = READY # not given\n",
    "        self.WORKING = WORKING # not given\n",
    "        self.DELIVERED = DELIVERED # not given\n",
    "        self.RECEIVED = RECEIVED # not given\n",
    "        self.CLOSE = CLOSE # not given\n",
    "        self.HOURS = HOURS # not given\n",
    "        self.HOURLY_RATE = HOURLY_RATE # not given\n",
    "        self.SELLING_HOURLY_PRICE = SELLING_HOURLY_PRICE\n",
    "        self.COST = COST # not given\n",
    "        self.QUALITY_EVALUATION = QUALITY_EVALUATION  # not given\n",
    "        self.MANUFACTURER = MANUFACTURER\n",
    "        self.MANUFACTURER_SECTOR = MANUFACTURER_SECTOR\n",
    "        self.MANUFACTURER_INDUSTRY_GROUP = MANUFACTURER_INDUSTRY_GROUP\n",
    "        self.MANUFACTURER_INDUSTRY = MANUFACTURER_INDUSTRY\n",
    "        self.MANUFACTURER_SUBINDUSTRY = MANUFACTURER_SUBINDUSTRY\n",
    "        self.MIN_QUALITY = MIN_QUALITY\n",
    "        self.WILDCARD = WILDCARD # WILDCARD: En el cas que no es puguin complir totes les concisions, quina es la que es pot saltar.\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Task Details:\\n\"\n",
    "            f\"  - Task ID: {self.TASK_ID}\\n\"\n",
    "            f\"  - Type: {self.TASK_TYPE}\\n\"\n",
    "            f\"  - Industry: {self.MANUFACTURER_INDUSTRY}\\n\"\n",
    "            f\"  - Start: {self.START}\\n\"\n",
    "            f\"  - End: {self.END}\\n\"\n",
    "            f\"  - Budget: {self.SELLING_HOURLY_PRICE}\\n\"\n",
    "            f\"  - Quality: {self.MIN_QUALITY}\\n\"\n",
    "            f\"  - Wildcard: {self.WILDCARD}\\n\"\n",
    "            f\"  - Source Language: {self.SOURCE_LANG}\\n\"\n",
    "            f\"  - Target Language: {self.TARGET_LANG}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_task():\n",
    "    \"\"\"\n",
    "    Generate a random task object with all the attributes that can be assigned at first\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pick a random manufacturer from the data_df (deber√≠a de ser con clients_df, pero luego hay que encontrar sus posibles industrias sector, subsector...)\n",
    "    manufacturer = data_df.sample(n=1).iloc[0] \n",
    "    # Select the corresponding client from clients_df \n",
    "    matching_client = clients_df[clients_df[\"CLIENT_NAME\"] == manufacturer[\"MANUFACTURER\"]]\n",
    "    # If the client is new (no registered in clients_df), we can assign a random wildcard\n",
    "    wildcard = matching_client[\"WILDCARD\"].values[0] if not matching_client.empty else random.choice(wildcards)    \n",
    "    \n",
    "    # Pick a possible pair of languages \n",
    "    language_pair = unique_language_pairs.sample(n=1).iloc[0]\n",
    "    \n",
    "    # Set the starting time to the current time\n",
    "    start = datetime.now()  \n",
    "    \n",
    "    return  Task(\n",
    "        PROJECT_ID=\"1\", #TODO que vaya aumentando de 1 en 1,\n",
    "        PM=random.choice(pm), \n",
    "        TASK_ID=1,\n",
    "        START=start,\n",
    "        END=start + timedelta(hours=random.randint(1, 3)), # example duration from 1 to 3 hours (toy example)\n",
    "        SELLING_HOURLY_PRICE= int(np.random.normal(loc=26, scale=7)),\n",
    "        MIN_QUALITY=random.choice(min_qualities),\n",
    "        WILDCARD=wildcard,\n",
    "        TASK_TYPE=random.choice(task_types),\n",
    "        SOURCE_LANG=language_pair[\"SOURCE_LANG\"],\n",
    "        TARGET_LANG=language_pair[\"TARGET_LANG\"],\n",
    "        MANUFACTURER=manufacturer[\"MANUFACTURER\"],\n",
    "        MANUFACTURER_SECTOR=manufacturer[\"MANUFACTURER_SECTOR\"],\n",
    "        MANUFACTURER_INDUSTRY_GROUP= manufacturer[\"MANUFACTURER_INDUSTRY_GROUP\"],\n",
    "        MANUFACTURER_INDUSTRY=manufacturer[\"MANUFACTURER_INDUSTRY\"],\n",
    "        MANUFACTURER_SUBINDUSTRY=manufacturer[\"MANUFACTURER_SUBINDUSTRY\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of what is happening\n",
    "\n",
    "In the global scope:\n",
    "\n",
    "0. We use as base of useful features the dataframe `transl_cost_pairs_df`\n",
    "\n",
    "1. We compute the **average proportional delay** (speed) for each translator and merge it with this base dataframe\n",
    "\n",
    "\n",
    "Now for the each task:\n",
    "\n",
    "2. We start to the strict filter:\n",
    "    - Filter of **languages**: only consider the translators who offer this translation\n",
    "    - Filter of **price**: only consider the prices below the threshold\n",
    "    - Filter of **quality** by language: this is done by making an average of the quality of these languages for each translator, and then using it as a threshold. \n",
    "    - Filter of **availability**: if the taks lasts less than 7 days we check whether the translator will even work before the theoretical deadline (it is 7 days because everyone works at least once a week)\n",
    "\n",
    "3. We do a **weighted knn**:\n",
    "    - We do it on the *perfect point* (price = 0, quality = 10, speed = 100%, experience = 10... (orientative values))\n",
    "    - The weights are chosen by the wildcards and by common sense (it may sound controversial or stupid but I can explain why consider this)\n",
    "        A weighted knn, after normalizing, it distorts the chosen axis size to give more or less weight. \n",
    "    - The similarity score is the final ranking. It is computed with the euclidian distance, but since we did these distortions, it is not very euclidean\n",
    "\n",
    "4. Outcome possibilities: ***(work in progress)***\n",
    "    - We get None or too few translators: if it is None we use the wildcard to completely ignore that factor in the strict filter\n",
    "    - We get a lot of translators: (we need the rest of features to give better recommendations)\n",
    "\n",
    "PD: some metrics can be improved, the quality is computed for each task (and probably more features). AND there are 3 mistakes in the datasets, which are pointed out at the bottom\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1742052911892,
     "user": {
      "displayName": "Rime Slaoui",
      "userId": "06907206809915164567"
     },
     "user_tz": -60
    },
    "id": "DdpXWG2XyfuP",
    "outputId": "704065d5-17d5-4fe8-fd7c-f45157aa07f6"
   },
   "outputs": [],
   "source": [
    "def compute_speed():\n",
    "    \"\"\"\n",
    "    Compute the speed/delay_percentage of each translator based on the average time taken to complete tasks.\n",
    "    The speed is calculated as the extra percentage of time taken compared to the expected time.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        translators_attributes_df (pd.DataFrame): Contains [name, source_lang, target_lang, hourly_rate, average_quality, delay_percentage].\n",
    "    \"\"\"\n",
    "    # Compute the delay of each task\n",
    "    data_df['DELAY_PERCENTAGE'] = ((data_df['DELIVERED'] - data_df['END']) / (data_df['END'] - data_df['START'])) * 100\n",
    "    data_df['DELAY_PERCENTAGE'] = data_df['DELAY_PERCENTAGE'].replace([np.inf, np.nan], 0)  # Replace inf and NaN with 0\n",
    "\n",
    "    # Limit the delay percentage to 100%\n",
    "    data_df['DELAY_PERCENTAGE'] = data_df['DELAY_PERCENTAGE'].clip(upper=100)  # Limitar a 100%\n",
    "\n",
    "    # Compute the mean delay percentage for each translator\n",
    "    avg_delay_by_translator = data_df.groupby('TRANSLATOR')['DELAY_PERCENTAGE'].mean().reset_index()\n",
    "    avg_delay_by_translator['DELAY_PERCENTAGE'] = avg_delay_by_translator['DELAY_PERCENTAGE'].round(2)\n",
    "\n",
    "    # Rename the column for clarity\n",
    "    avg_delay_by_translator.rename(columns={'DELAY_PERCENTAGE': 'AVG_DELAY_PERCENTAGE'}, inplace=True)\n",
    "\n",
    "    # Merge the average delay with the translator cost pairs DataFrame\n",
    "    translators_attributes_df = transl_cost_pairs_df.merge(avg_delay_by_translator, on='TRANSLATOR', how='left')\n",
    "\n",
    "\n",
    "    #TODO hay un problema con esto y es que si le han asignado la tarea tarde, o empieza a trabajar m√°s tarde (por horario), √©l puede arrastrar esto y no es culpa suya.\n",
    "    #tambi√©n deberia influir la cantidad de tareas que ha hecho, porque puede haber sido excepcional si tiene pocas\n",
    "    \n",
    "    return translators_attributes_df\n",
    "\n",
    "\n",
    "\n",
    "def compute_quality_by_languages(df_filtered):\n",
    "    \"\"\"\n",
    "    Computes the average translation quality for each translator.\n",
    "    It calculates the average quality for a given language pair. \n",
    "    It fills in exceptional missing values with the translator's average quality for other languages (with a penalty adjustment).\n",
    "\n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            DataFrame containing filtered translators' attributes (price & language).\n",
    "\n",
    "    Returns:\n",
    "        df_filtered (pd.DataFrame):\n",
    "            DataFrame with an additional column for average quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter by quality\n",
    "    filtered_translators = df_filtered['TRANSLATOR'].unique()\n",
    "    \n",
    "    # Calcular calidad promedio por traductor y par de idiomas\n",
    "    quality_by_translator = (\n",
    "        data_df[data_df['TRANSLATOR'].isin(filtered_translators)]\n",
    "        .groupby(['TRANSLATOR', 'SOURCE_LANG', 'TARGET_LANG'])['QUALITY_EVALUATION']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .reset_index()\n",
    "        .rename(columns={'QUALITY_EVALUATION': 'AVERAGE_QUALITY'})\n",
    "    )\n",
    "    \n",
    "    # Merge to add this average quality\n",
    "    df_filtered = df_filtered.merge(\n",
    "        quality_by_translator,\n",
    "        on=['TRANSLATOR', 'SOURCE_LANG', 'TARGET_LANG'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # if someone has no registers of translations in these languages we set it to its average quality \n",
    "    translators_without_lang_experience = df_filtered[df_filtered['AVERAGE_QUALITY'].isna()]['TRANSLATOR'].unique()\n",
    "    general_quality = (\n",
    "        data_df[data_df['TRANSLATOR'].isin(translators_without_lang_experience)]\n",
    "        .groupby('TRANSLATOR')['QUALITY_EVALUATION']\n",
    "        .mean() \n",
    "        .round(2) - 1 # penalization, quiz√°s debamos marcar que adem√°s no tuvieron experiencia en estos idiomas\n",
    "    )\n",
    "\n",
    "    df_filtered.loc[df_filtered['AVERAGE_QUALITY'].isna(), 'AVERAGE_QUALITY'] = (\n",
    "        df_filtered.loc[df_filtered['AVERAGE_QUALITY'].isna(), 'TRANSLATOR']\n",
    "        .map(general_quality)\n",
    "    )\n",
    "\n",
    "\n",
    "    # if there is someone who doesn't have any registry at all of a single task, fill with general global mean but penalized (?)\n",
    "    df_filtered['AVERAGE_QUALITY'] = df_filtered['AVERAGE_QUALITY'].fillna(data_df['QUALITY_EVALUATION'].mean() - 1.5)\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# Ahora nos fijaremos en si habra alguna instancia en la linea de tiempo esperada (START - END) en la que el traductor trabaje\n",
    "# porque como no tenemos ni idea de cu√°nto va a durar, pues nos da igual y lo simplificamos\n",
    "def available_translators(task, df_filtered):\n",
    "    \"\"\"\n",
    "    Check the availability of translators for a given task based on their schedules.\n",
    "    If a translator is available for any part of the task's deadline, they are considered available.\n",
    "    \n",
    "    Args:\n",
    "        task (Task object):\n",
    "            The task for which we want to check the availability of translators. We use it to know the start and theoretical end of the task.\n",
    "        df_filtered: DataFrame\n",
    "            DataFrame containing the filtered translators' attributes of price, language, and quality.\n",
    "    \n",
    "    Returns:\n",
    "        mask (List[bool]):\n",
    "            A list of booleans that map to each translator in df_filtered, indicating their availability for the task.\n",
    "    \"\"\"\n",
    "    weekday_map = {\n",
    "        0: 'MON',\n",
    "        1: 'TUES',\n",
    "        2: 'WED',\n",
    "        3: 'THURS',\n",
    "        4: 'FRI',\n",
    "        5: 'SAT',\n",
    "        6: 'SUN'\n",
    "    }\n",
    "\n",
    "    task_start = task.START\n",
    "    task_end = task.END\n",
    "    mask = []\n",
    "\n",
    "    \n",
    "    # If the duration of the task is more than 7 days, there are no availability restrictions (everyone works at least once a week)\n",
    "    if (task_end - task_start).days > 7:\n",
    "        return [True] * len(df_filtered) # All translators are available\n",
    "\n",
    "\n",
    "    # Filtrar schedules_df para que solo contenga los traductores v√°lidos de df_filtered, para poder iterar √∫nicamente sobre ellos\n",
    "    # Esto es necesario porque schedules_df puede contener traductores que no est√°n en df_filtered\n",
    "    valid_translators = df_filtered[\"TRANSLATOR\"].tolist()  # Obtener la lista de nombres v√°lidos\n",
    "    filtered_schedules = schedules_df[schedules_df[\"NAME\"].isin(valid_translators)]\n",
    "\n",
    "    \n",
    "    for _, row in filtered_schedules.iterrows():\n",
    "        translator_available = False\n",
    "        current = task_start\n",
    "\n",
    "        while current <= task_end:\n",
    "            day_col = weekday_map[current.weekday()]  # 'MON', 'TUES', etc.\n",
    "\n",
    "            if row[day_col] == 1:\n",
    "                # Parse START and END as datetime.time if needed\n",
    "                if isinstance(row['START'], str):\n",
    "                    start_time = datetime.strptime(row['START'], \"%H:%M:%S\").time()\n",
    "                    end_time = datetime.strptime(row['END'], \"%H:%M:%S\").time()\n",
    "                else:\n",
    "                    start_time = row['START']\n",
    "                    end_time = row['END']\n",
    "\n",
    "                translator_start = datetime.combine(current.date(), start_time)\n",
    "                translator_end = datetime.combine(current.date(), end_time)\n",
    "\n",
    "                # Comprobar si hay solapamiento con la tarea\n",
    "                if translator_end > task_start and translator_start < task_end:\n",
    "                    translator_available = True\n",
    "                    break  # No hace falta seguir buscando si ya hay solapamiento\n",
    "\n",
    "            # Pasamos al siguiente d√≠a\n",
    "            current += timedelta(days=1)\n",
    "            current = current.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "        mask.append(translator_available)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def filter_language_price_quality_availability(translators_attributes_df, task = Task, need_wildcard = False):\n",
    "    \"\"\"\n",
    "    Filters the translators' attributes of languages, price, quality, and availability.\n",
    "    If need_wildcard is True, it will skip the filter corresponding to the wildcard.\n",
    "    \n",
    "    Args:\n",
    "        translators_attributes_df (pd.DataFrame): \n",
    "            DataFrame containing the translators' attributes (name, languages, price, speed).\n",
    "        task (Task object): \n",
    "            The task for which we want to filter the translators.\n",
    "        need_wildcard (bool): \n",
    "            If True, skip the filter corresponding to the wildcard.\n",
    "            \n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            Filtered DataFrame containing translators who meet the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not need_wildcard:\n",
    "        # Filter by language, price \n",
    "        df_filtered = translators_attributes_df[\n",
    "            (translators_attributes_df['SOURCE_LANG'] == task.SOURCE_LANG) & #TODO tener en cuenta la posibilidad de ofrecer tambi√©n varios Spanish (como el iberian, latamer, etc. o con el ingl√©s)?\n",
    "            (translators_attributes_df['TARGET_LANG'] == task.TARGET_LANG) &\n",
    "            (translators_attributes_df['HOURLY_RATE'] <= task.SELLING_HOURLY_PRICE) \n",
    "        ].copy()\n",
    "\n",
    "        # add the average quality column\n",
    "        df_filtered = compute_quality_by_languages(df_filtered)\n",
    "        df_filtered = df_filtered[df_filtered['AVERAGE_QUALITY'] >= task.MIN_QUALITY]\n",
    "\n",
    "        # Filter by availability\n",
    "        availability_mask = available_translators(task, df_filtered)\n",
    "        valid_translators = [name for name, available in zip(df_filtered[\"TRANSLATOR\"], availability_mask) if available]\n",
    "        return df_filtered[df_filtered[\"TRANSLATOR\"].isin(valid_translators)]\n",
    "    \n",
    "    # same code as above but with the wildcard, it will skip the filter corresponding to the wildcard\n",
    "    else:\n",
    "        # Filter by language, price \n",
    "        df_filtered = translators_attributes_df[\n",
    "            (translators_attributes_df['SOURCE_LANG'] == task.SOURCE_LANG) & #TODO tener en cuenta la posibilidad de ofrecer tambi√©n varios Spanish (como el iberian, latamer, etc. o con el ingl√©s)?\n",
    "            (translators_attributes_df['TARGET_LANG'] == task.TARGET_LANG) &\n",
    "            (translators_attributes_df['HOURLY_RATE'] <= task.SELLING_HOURLY_PRICE) if task.WILDCARD != \"Price\" else True \n",
    "        ].copy()\n",
    "\n",
    "        if task.WILDCARD != \"Quality\":\n",
    "            # add the average quality column\n",
    "            df_filtered = compute_quality_by_languages(df_filtered)\n",
    "            df_filtered = df_filtered[df_filtered['AVERAGE_QUALITY'] >= task.MIN_QUALITY]\n",
    "\n",
    "        if task.WILDCARD != \"Deadline\":\n",
    "            # Filter by availability\n",
    "            availability_mask = available_translators(task, df_filtered)\n",
    "            valid_translators = [name for name, available in zip(df_filtered[\"TRANSLATOR\"], availability_mask) if available]\n",
    "            return df_filtered[df_filtered[\"TRANSLATOR\"].isin(valid_translators)]\n",
    "        else:\n",
    "            return df_filtered\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_knn(df_filtered, task = Task, need_wildcard = False):\n",
    "    \"\"\"\n",
    "    Performs K-Nearest Neighbors (KNN) to find the best translators based on the task's requirements.\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            DataFrame containing the filtered translators' attributes (name, language, price, quality, speed).\n",
    "        task (Task object): \n",
    "            We only need it to know the wildcard\n",
    "        need_wildcard (bool): \n",
    "            If True, remove the dimension of the wildcard from the KNN (since it will not be in the df_filtered).\n",
    "            \n",
    "    Returns:\n",
    "        distances (np.ndarray): \n",
    "            Distances of the nearest neighbors.\n",
    "        indexes (np.ndarray): \n",
    "            Indices of the nearest neighbors in the original DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the numeric features for the KNN (the order is important through the whole process)\n",
    "    \n",
    "    if not need_wildcard:\n",
    "        X = df_filtered[['HOURLY_RATE', 'AVERAGE_QUALITY', 'AVG_DELAY_PERCENTAGE']]\n",
    "    elif task.WILDCARD == \"Price\":\n",
    "        X = df_filtered[['AVERAGE_QUALITY', 'AVG_DELAY_PERCENTAGE']]\n",
    "    elif task.WILDCARD == \"Quality\":\n",
    "        X = df_filtered[['HOURLY_RATE', 'AVG_DELAY_PERCENTAGE']]\n",
    "    elif task.WILDCARD == \"Deadline\":\n",
    "        X = df_filtered[['HOURLY_RATE', 'AVERAGE_QUALITY']]\n",
    "\n",
    "    # Standarize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Definir pesos para las caracter√≠sticas, thumb rule.\n",
    "    weights = np.array([1, 1.5, 0.25])  # The smaller the weight, the less important the feature is\n",
    "                                        # Por qu√© calidad m√°s? clients_df[\"WILDCARD\"].value_counts(), vemos que la tendencia es a calidad\n",
    "                                        # literalmente, para decidir el mejor, todo depende de los GUSTOS del cliente\n",
    "\n",
    "    # lo he dejado aqu√≠ para que no perdamos el hilo\n",
    "    if not need_wildcard:\n",
    "        # Start defining the wildcard vector\n",
    "        wildcard_vector = np.ones_like(weights)\n",
    "        \n",
    "        # Modificar la ponderaci√≥n seg√∫n 'task.WILDCARD' porque la wildcard tambi√©n habla de sus preferencias, sus gustos, \n",
    "        # que al final del d√≠a es absolutamente el √∫nico factor para ordenar los traductores, no?\n",
    "        if task.WILDCARD == 'Price':\n",
    "            wildcard_vector[0] = 0.25  \n",
    "        elif task.WILDCARD == 'Quality':\n",
    "            wildcard_vector[1] = 0.25 \n",
    "        elif task.WILDCARD == 'Deadline':\n",
    "            wildcard_vector[2] = 0.25 \n",
    "        \n",
    "        weights = weights * wildcard_vector  \n",
    "        \n",
    "    # Apply weights to the features\n",
    "    X_weighted = X_scaled * weights\n",
    "\n",
    "    # Train\n",
    "    knn = NearestNeighbors(metric='euclidean')  #TODO maybe other ways\n",
    "    knn.fit(X_weighted)                                         # We can limit the n_neighbors or without limit. \n",
    "                                # If it is limited, when the client in the page wants to see more, we can discard the first 15 and do knn again with the rest.\n",
    "\n",
    "    # Ideal outcome\n",
    "    task_df = pd.DataFrame([[0, 10, -100]], # ideal values\n",
    "                        columns=['HOURLY_RATE', 'AVERAGE_QUALITY', 'AVG_DELAY_PERCENTAGE'])  # tranform to dataframe to help the knn to compute it\n",
    "    task_scaled = scaler.transform(task_df)\n",
    "    task_weighted = task_scaled * weights  # Weight the task too\n",
    "\n",
    "    # Find nearest neighbours\n",
    "    distances, indexes = knn.kneighbors(task_weighted)\n",
    "    \n",
    "    return distances, indexes\n",
    "\n",
    "\n",
    "\n",
    "def get_best_translators(df_filtered, indexes, distances):\n",
    "    \"\"\"\n",
    "    Get the best translators based on the KNN results.\n",
    "    \n",
    "    Args:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            Contains the filtered translators' attributes (name, language, price, quality, speed).\n",
    "        indexes (np.ndarray): \n",
    "            Indices of the nearest neighbors in the df_filtered.\n",
    "        distances (np.ndarray): \n",
    "            Distances of the nearest neighbors.\n",
    "            \n",
    "    Returns:\n",
    "        df_filtered (pd.DataFrame): \n",
    "            Contains the filtered translators' attributes (name, language, price, quality, speed AND similarity_score).\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_translators = df_filtered.iloc[indexes[0]].copy()\n",
    "    \n",
    "    # Add the similarity score\n",
    "    selected_translators['Similarity Score'] = distances[0].round(2)  # Round to 2 decimal places\n",
    "\n",
    "    # Sort by similarity score (ascending: closest match first)\n",
    "    selected_translators = selected_translators.sort_values(by='Similarity Score', ascending=True) # \n",
    "\n",
    "    return selected_translators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe like transl_cost_pairs_df but with information about the delay\n",
    "translators_attributes_df = compute_speed()\n",
    "\n",
    "# Example of generating a task\n",
    "new_task = generate_task()\n",
    "tasks = []\n",
    "tasks.append(new_task)\n",
    "\n",
    "for task in tasks:\n",
    "    need_wildcard = False\n",
    "    print(\"New task:\")\n",
    "    print(task)\n",
    "    #TODO es esto ineficiente?\n",
    "    df_filtered = filter_language_price_quality_availability(translators_attributes_df, new_task)\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        print(\"\\nNo available translators. Possible reasons:\")\n",
    "        print(\"1. No translators available because the deadline is too short\")\n",
    "        print(\"2. No translators available because the quality is too high\")\n",
    "        print(\"3. No translators available because the price is too low\")\n",
    "        print(\"PD: the possible selection of languages to translate is assured to exist in the generate_task function\")\n",
    "        print(\"\\nTrying with the wildcard...\\n\")        \n",
    "        need_wildcard = True\n",
    "        df_filtered = filter_language_price_quality_availability(translators_attributes_df, new_task, need_wildcard = need_wildcard)\n",
    "        if df_filtered.empty:\n",
    "            print(\"No available translators even with the wildcard\")\n",
    "            #TODO implement, see which is the strict filter or something inside the function to know the remedy\n",
    "            # ofrecer ignorando calidad, precio y deadline. Y si ni siquiera as√≠ hay, pues ofrecer otros idiomas parecidos (espa√±ol vs argentino, english uk vs english us, etc.)\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    # Compute the KNN\n",
    "    distances, indexes = do_knn(df_filtered, task, need_wildcard = need_wildcard)\n",
    "\n",
    "    # Get the dataframe with the best translators\n",
    "    best_translators_df = get_best_translators(df_filtered, indexes, distances)\n",
    "    display(best_translators_df)\n",
    "\n",
    "    \n",
    "    \n",
    "# TODO: what I am thinking next\n",
    "# availability, quizas debamos tener en cuenta cuantas horas trabaja a la semana (si dura +7 dias ?), se consideraria como velocidad\n",
    "\n",
    "# relaci√≥n cliente traductor\n",
    "# experiencia en pareja de idioma:    veces u horas de traduccion para este par de idiomas,\n",
    "# velocidad:    horas que trabaja a la semana o rapidez de entrega\n",
    "# experiencia en sector\n",
    "# experiencia en el tipo de tarea\n",
    "# si cumpliste con las expectativas de calidad?\n",
    "# poner una opci√≥n de sus preferencias para usarlo en los weights? (relacion calidad precio...), porque quizas si pone mucho dinero de presupuesto es para tener mejor de las demas caracter√≠sticas\n",
    "# lo mismo con la calidad, quizas pide poca para que el precio sea bajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 types of mistakes in the dataset, they are listed in the 3 below cells, with its solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hay 13 que tiene el horario de salida (END) con un valor y tipo incorrecto\n",
    "# # END de schedules que no son datetime.time\n",
    "# # Ver filas donde END no es datetime.time\n",
    "# invalid_rows = schedules_df.loc[\n",
    "#     ~schedules_df[\"END\"].apply(lambda x: isinstance(x, datetime.time) if isinstance(x, datetime.time) or isinstance(x, str) else False)\n",
    "# ]\n",
    "\n",
    "# display((invalid_rows))\n",
    "\n",
    "# # Substituimos este valor por los que tenemos registrados en data_df\n",
    "# # Extraer la hora del dataframe hist√≥rico data_df y asignarla a las filas incorrectas\n",
    "# for index, row in invalid_rows.iterrows():\n",
    "#     # Buscar el nombre en data_df\n",
    "#     historical_entry = data_df[data_df[\"TRANSLATOR\"] == row[\"NAME\"]]\n",
    "\n",
    "#     if not historical_entry.empty:\n",
    "#         # Extraer solo la hora de START ignorando la fecha\n",
    "#         correct_time = historical_entry.iloc[0][\"END\"].time()\n",
    "\n",
    "#         # Reemplazar el valor incorrecto en schedules_df\n",
    "#         schedules_df.at[index, \"END\"] = correct_time\n",
    "\n",
    "# # FIXED\n",
    "# # GUARDAR EL NUEVO EXCEL\n",
    "# # schedules_df.to_excel(os.path.join(data_path, \"Schedules_fixed.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay algunos con fecha de START == END y si START > ASSIGNED (son errores porque no tiene sentido); pero si START <= ASSIGNED, \n",
    "# probablemente signifique que END (deadline) era urgente y no puso fecha l√≠mite, no son errores\n",
    "\n",
    "\n",
    "# provisionalmente cambiamos el START como ASSIGNED para estos casos\n",
    "# data_df.loc[data_df['START'] >= data_df['ASSIGNED'], 'START'] = data_df['ASSIGNED'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay 1 fecha irreal (a√±o 1201)\n",
    "# def detectar_fechas_fuera_de_rango(col):\n",
    "#     fechas_parsed = pd.to_datetime(data_df[col], errors='coerce', dayfirst=True)\n",
    "#     fechas_originales = data_df[col]\n",
    "#     fechas_invalidas = fechas_originales[fechas_parsed.isna()]\n",
    "#     return fechas_invalidas\n",
    "\n",
    "# # Aplicarlo a tus columnas:\n",
    "# fechas_start_invalidas = detectar_fechas_fuera_de_rango('START')\n",
    "# fechas_end_invalidas = detectar_fechas_fuera_de_rango('END')\n",
    "# fechas_delivered_invalidas = detectar_fechas_fuera_de_rango('DELIVERED')\n",
    "\n",
    "# # Mostrarlas\n",
    "# print(\"Fechas START inv√°lidas:\\n\", fechas_start_invalidas)\n",
    "# print(\"Fechas END inv√°lidas:\\n\", fechas_end_invalidas)\n",
    "# print(\"Fechas DELIVERED inv√°lidas:\\n\", fechas_delivered_invalidas)\n",
    "\n",
    "# # Suponiendo que la fecha problem√°tica est√° en la columna 'START'\n",
    "# data_df['START'] = data_df['START'].replace(\"29/05/1201 18:00:00\", \"29/04/2012 18:00:00\")\n",
    "\n",
    "# # Ahora convierte la columna de nuevo\n",
    "# data_df['START'] = pd.to_datetime(data_df['START'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# print(data_df[data_df['START'] == '29/04/2012 18:00:00'])\n",
    "#check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
